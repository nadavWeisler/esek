{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohens Kappa: 0.1176470588235292\n",
      "p_value: 0.4518653329790838\n",
      "Statistic: 0.7523118184738425\n",
      "Standard_Error_H0: 0.24289203320073627\n",
      "Standart_Error_Fleisse, Cohen & Everett: 0.15638071333531725\n",
      "p_value (Fleisse, Cohen & Everett): 0.6281318310112067\n",
      "Statistic (Fleisse, Cohen & Everett): 0.4843594796964818\n",
      "Confidence Intervals Kappa: (-0.1889, 0.4242)\n",
      "Confidence Intervals Kappa_H0: (-0.3584, 0.5937)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def calculate_p_value_from_z_score(score):\n",
    "    p_value = st.t.sf((abs(score)), 100000) * 2\n",
    "    return min(float(p_value), 0.99999)\n",
    "\n",
    "#Cohens Kappa fpr two raters\n",
    "#contingency_table = np.array([[106,10,4],[22,28,10],[2,12,6]])\n",
    "contingency_table = np.array([[4,4,2],[2,6,0],[0,2,0]])\n",
    "#contingency_table = np.array([[10,4,1],[6,16,2],[0,3,8]])\n",
    "#contingency_table2 = np.array([[20,5],[10,15]])\n",
    "values = [1, 0, 0.4412, 0, 1, 0.67, 0.4412, 0.67, 1]\n",
    "\n",
    "# Create a 3x3 matrix\n",
    "matrix = np.array(values).reshape((3, 3))\n",
    "\n",
    "confidence_level = 0.95\n",
    "\n",
    "def Cohens_Kappa_2_raters(contingency_table, confidence_level, weights_type='equal-spacing'):\n",
    "    number_of_levels = contingency_table.shape[1]\n",
    "    Sample_Size = np.sum(contingency_table)\n",
    "    Sum_of_coloumns = np.sum(contingency_table, axis=0) / Sample_Size\n",
    "    Sum_of_rows = np.sum(contingency_table, axis=1) / Sample_Size\n",
    "    if weights_type == 'equal-spacing':\n",
    "        Weights_Matrix = 1 - abs(np.subtract.outer(np.arange(1, number_of_levels+1), np.arange(1, number_of_levels+1))) / (number_of_levels-1)\n",
    "    elif weights_type == 'fleiss':\n",
    "        Weights_Matrix = 1 - (abs(np.subtract.outer(np.arange(1, number_of_levels+1), np.arange(1, number_of_levels+1))) / (number_of_levels-1))**2\n",
    "\n",
    "\n",
    "    Percentages_of_Agreement = np.sum(Weights_Matrix * contingency_table)/ Sample_Size\n",
    "    Percentages_Of_Disagreement = np.sum(Weights_Matrix * np.outer(Sum_of_rows, Sum_of_coloumns))\n",
    "    Cohens_Kappa = (Percentages_of_Agreement - Percentages_Of_Disagreement) / (1 - Percentages_Of_Disagreement)\n",
    "\n",
    "    # Calculate the Variance (Fleiss, Cohen & Everrit, 1969)\n",
    "    Agreement_Matrix = np.eye(contingency_table.shape[1])\n",
    "    Probabilty_Matrix = (contingency_table)/Sample_Size\n",
    "    Variance_Matrix = np.subtract((np.subtract(Weights_Matrix.T, (np.dot(Weights_Matrix, np.sum(Probabilty_Matrix, axis=1)) * (1 - Cohens_Kappa))).T), np.dot(Weights_Matrix, np.sum(Probabilty_Matrix, axis=0)) * (1 - Cohens_Kappa)).T\n",
    "    Standart_Error_Kappa_Fleisse = np.sqrt((np.sum(Probabilty_Matrix * Variance_Matrix**2) - (Cohens_Kappa - Percentages_Of_Disagreement * (1 - Cohens_Kappa))**2) / np.inner(1 - Percentages_Of_Disagreement, 1 - Percentages_Of_Disagreement) / Sample_Size)\n",
    "    \n",
    "    # Calculate the Variance of H0\n",
    "    Outer_Probability_Matrix = np.multiply.outer(Sum_of_coloumns, Sum_of_rows)\n",
    "    Sum_of_rows = np.sum(np.sum(Probabilty_Matrix,axis = 0) * Weights_Matrix,axis = 1)\n",
    "    Sum_of_coloumns = np.sum(np.sum(Probabilty_Matrix,axis = 1) * Weights_Matrix,axis = 1)\n",
    "    Weighted_Variance_Matrix = (Weights_Matrix - np.add.outer(Sum_of_rows,Sum_of_coloumns))**2\n",
    "    term = np.sum(Outer_Probability_Matrix * Weighted_Variance_Matrix)\n",
    "    Standard_Error_H0 = np.sqrt((term - Percentages_Of_Disagreement**2) / (Sample_Size* (1-Percentages_Of_Disagreement)**2))\n",
    "\n",
    "    # Signficance\n",
    "    StatisticH0 = Cohens_Kappa / Standart_Error_Kappa_Fleisse\n",
    "    p_valueH0 = calculate_p_value_from_z_score(StatisticH0)\n",
    "    Statistic_Fleiss = Cohens_Kappa / Standard_Error_H0\n",
    "    p_value_Fleiss = calculate_p_value_from_z_score(Statistic_Fleiss)\n",
    "\n",
    "    # Confidence Interval\n",
    "    zcrit = st.t.ppf(1 - (1 - confidence_level) / 2, 100000)\n",
    "    Lower_Confidence_Interval_Kappa = Cohens_Kappa - Standart_Error_Kappa_Fleisse*zcrit\n",
    "    Upper_Confidence_Interval_Kappa = Cohens_Kappa + Standart_Error_Kappa_Fleisse*zcrit\n",
    "    Lower_Confidence_Interval_Kappa_H0 = Cohens_Kappa - Standard_Error_H0*zcrit\n",
    "    Upper_Confidence_Interval_Kappa_H0 = Cohens_Kappa + Standard_Error_H0*zcrit\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    results[\"Cohens Kappa\"]= Cohens_Kappa\n",
    "    results[\"p_value\"] = p_valueH0\n",
    "    results[\"Statistic\"]= StatisticH0\n",
    "    results[\"Standard_Error_H0\"]= Standard_Error_H0\n",
    "    results[\"Standart_Error_Fleisse, Cohen & Everett\"] = Standart_Error_Kappa_Fleisse\n",
    "    results[\"p_value (Fleisse, Cohen & Everett)\"] = p_value_Fleiss\n",
    "    results[\"Statistic (Fleisse, Cohen & Everett)\"]= Statistic_Fleiss\n",
    "    results[\"Confidence Intervals Kappa\"] = f\"({round(Lower_Confidence_Interval_Kappa, 4)}, {round(Upper_Confidence_Interval_Kappa, 4)})\"\n",
    "    results[\"Confidence Intervals Kappa_H0\"] = f\"({round(Lower_Confidence_Interval_Kappa_H0, 4)}, {round(Upper_Confidence_Interval_Kappa_H0, 4)})\"\n",
    "\n",
    "    result_str = \"\\n\".join([f\"{key}: {value}\" for key, value in results.items()])\n",
    "    return result_str\n",
    "\n",
    "a = Cohens_Kappa_2_raters(contingency_table, confidence_level)\n",
    "#b = Cohens_Kappa_2_raters(contingency_table2, confidence_level)\n",
    "\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
