{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "\n",
    "def calculate_p_value_from_z_score(score):\n",
    "    p_value = st.t.sf((abs(score)), 100000) * 2\n",
    "    return min(float(p_value), 0.99999)\n",
    "\n",
    "#Cohens Kappa fpr two raters\n",
    "contingency_table = np.array([[106,10,4],[22,28,10],[2,12,6]])\n",
    "contingency_table = np.array([[4,4,2],[2,6,0],[0,2,0]])\n",
    "#contingency_table = np.array([[10,4,1],[6,16,2],[0,3,8]])\n",
    "#contingency_table2 = np.array([[20,5],[10,15]])\n",
    "\n",
    "confidence_level = 0.95\n",
    "\n",
    "def Cohens_Kappa_2_raters(contingency_table, confidence_level):\n",
    "    Sample_Size = np.sum(contingency_table)\n",
    "    Diagonal_of_Agreement = np.diag(contingency_table)\n",
    "    Sum_of_coloumns = np.sum(contingency_table, axis=0) / Sample_Size\n",
    "    Sum_of_rows = np.sum(contingency_table, axis=1) / Sample_Size\n",
    "    Disagreement_Table = np.outer(Sum_of_coloumns, Sum_of_rows)\n",
    "    Percentages_of_DissAgreement = np.trace(Disagreement_Table)\n",
    "    Percentages_of_Agreement = np.sum((Diagonal_of_Agreement)/ Sample_Size)\n",
    "    Cohens_Kappa = (Percentages_of_Agreement - Percentages_of_DissAgreement) / (1 - Percentages_of_DissAgreement)\n",
    "\n",
    "    # Calculate the Variance (Fleiss, Cohen & Everrit, 1969)\n",
    "    number_of_levels = contingency_table.shape[1]\n",
    "    Agreement_Matrix = np.eye(contingency_table.shape[1])\n",
    "    Probabilty_Matrix = (contingency_table/Sample_Size)\n",
    "    Probability_Coloumns = np.repeat(np.sum(Probabilty_Matrix, axis=1) * (1-Cohens_Kappa), repeats=number_of_levels)\n",
    "    Probability_Rows = np.repeat((np.sum(Probabilty_Matrix, axis=0) * (1 - Cohens_Kappa))[np.newaxis, :], repeats=number_of_levels, axis=0)\n",
    "    Final_Probabilities = np.transpose(Probabilty_Matrix).flatten() * (Agreement_Matrix.flatten() -  Probability_Coloumns - Probability_Rows.flatten())**2\n",
    "    Standart_Error_Kappa_Fleisse = np.sqrt((np.sum(Final_Probabilities) - (Cohens_Kappa - Percentages_of_DissAgreement * (1 - Cohens_Kappa))**2) / (1-Percentages_of_DissAgreement)**2 / Sample_Size)\n",
    "\n",
    "    # Calculate the Variance for H0 (Fleiss, Cohen & Everrit, 1969)\n",
    "    outer_mulitiplication_matrix = np.transpose(np.outer(Sum_of_rows, Sum_of_coloumns))\n",
    "    outer_addition_matrix = np.add.outer(Sum_of_rows, Sum_of_coloumns)\n",
    "    Variance_matrix = outer_mulitiplication_matrix * (Agreement_Matrix - outer_addition_matrix)**2\n",
    "    Standard_Error_H0 = np.sqrt((np.sum(Variance_matrix) - Percentages_of_DissAgreement**2) / (Sample_Size * (1-Percentages_of_DissAgreement)**2))\n",
    "\n",
    "    # Signficance\n",
    "    StatisticH0 = Cohens_Kappa / Standard_Error_H0\n",
    "    p_valueH0 = calculate_p_value_from_z_score(StatisticH0)\n",
    "    Statistic_Fleiss = Cohens_Kappa / Standart_Error_Kappa_Fleisse\n",
    "    p_value_Fleiss = calculate_p_value_from_z_score(Statistic_Fleiss)\n",
    "\n",
    "    # Confidence Interval\n",
    "    zcrit = st.t.ppf(1 - (1 - confidence_level) / 2, 100000)\n",
    "    Lower_Confidence_Interval_Kappa = Cohens_Kappa - Standart_Error_Kappa_Fleisse*zcrit\n",
    "    Upper_Confidence_Interval_Kappa = Cohens_Kappa + Standart_Error_Kappa_Fleisse*zcrit\n",
    "    Lower_Confidence_Interval_Kappa_H0 = Cohens_Kappa - Standard_Error_H0*zcrit\n",
    "    Upper_Confidence_Interval_Kappa_H0 = Cohens_Kappa + Standard_Error_H0*zcrit\n",
    "\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    results[\"Cohens Kappa\"]= Cohens_Kappa\n",
    "    results[\"p_value\"] = p_valueH0\n",
    "    results[\"Statistic\"]= StatisticH0\n",
    "    results[\"Standard_Error_H0\"]= Standard_Error_H0\n",
    "    results[\"Standart_Error_Fleisse, Cohen & Everett\"] = Standart_Error_Kappa_Fleisse\n",
    "    results[\"p_value (Fleisse, Cohen & Everett)\"] = p_value_Fleiss\n",
    "    results[\"Statistic (Fleisse, Cohen & Everett)\"]= Statistic_Fleiss\n",
    "    results[\"Confidence Intervals Kappa\"] = f\"({round(Lower_Confidence_Interval_Kappa, 4)}, {round(Upper_Confidence_Interval_Kappa, 4)})\"\n",
    "    results[\"Confidence Intervals Kappa_H0\"] = f\"({round(Lower_Confidence_Interval_Kappa_H0, 4)}, {round(Upper_Confidence_Interval_Kappa_H0, 4)})\"\n",
    "\n",
    "    result_str = \"\\n\".join([f\"{key}: {value}\" for key, value in results.items()])\n",
    "    return result_str\n",
    "\n",
    "a = Cohens_Kappa_2_raters(contingency_table, confidence_level)\n",
    "#b = Cohens_Kappa_2_raters(contingency_table2, confidence_level)\n",
    "\n",
    "print(a)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
