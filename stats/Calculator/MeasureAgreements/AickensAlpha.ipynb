{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Aiken's Alpha\": 0.4006062801486114,\n",
       " \"Aiken's Standard Deviation \": 0.08468763496148539,\n",
       " 'Confidence Intervals': '(0.2346, 0.5666)'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "data = np.array([55, 10, 2, 6, 4, 10, 2, 5, 6])\n",
    "\n",
    "\n",
    "def Aiken_Alpha(contingency_table, confidence_level):\n",
    "    \n",
    "    y = np.reshape(contingency_table, (int(np.sqrt(len(contingency_table))), -1))\n",
    "\n",
    "    # Calculation of Cohen's Kappa\n",
    "    Weights_matrix = np.eye(y.shape[0])\n",
    "    confidence_Level = 0.95\n",
    "    Number_Of_Levels = y.shape[0]\n",
    "    y = y + 1 / (Number_Of_Levels**2)\n",
    "    Sample_Size = np.sum(y)\n",
    "    Weighted_Sum = np.sum(y * Weights_matrix)\n",
    "    Observed_Agreement = Weighted_Sum / Sample_Size\n",
    "    Sum_Of_Rows = np.sum(y, axis=1)\n",
    "    Sum_Of_Coloumns = np.sum(y, axis=0)\n",
    "    Probability_Rows = Sum_Of_Rows / Sample_Size\n",
    "    Probability_Coloumns = Sum_Of_Coloumns / Sample_Size\n",
    "    Expected_Agreement = np.sum(np.tile(Probability_Coloumns, (Number_Of_Levels, 1)) * Probability_Rows.reshape(-1, 1) * Weights_matrix)\n",
    "    alpha = (Observed_Agreement - Expected_Agreement) / (1 - Expected_Agreement)\n",
    "\n",
    "    # Calculation of Aiken's Alpha\n",
    "    continue_loop = True\n",
    "    while continue_loop:\n",
    "        previous_alpha = alpha\n",
    "        pr_denominator = Sample_Size * (1 - alpha + alpha * np.dot(Weights_matrix, Probability_Coloumns) / Expected_Agreement)\n",
    "        Probability_Rows = Sum_Of_Rows / pr_denominator\n",
    "        Probability_Rows[0] = 1 - np.sum(Probability_Rows[1:])\n",
    "        pc_denominator = Sample_Size * (1 - alpha + alpha * np.dot(Probability_Rows, Weights_matrix) / Expected_Agreement)\n",
    "        Probability_Coloumns = Sum_Of_Coloumns / pc_denominator\n",
    "        Probability_Coloumns[0] = 1 - np.sum(Probability_Coloumns[1:])\n",
    "        Expected_Agreement = np.sum(np.tile(Probability_Coloumns, (Number_Of_Levels, 1)) * Probability_Rows.reshape(-1, 1) * Weights_matrix)\n",
    "        alpha = (Observed_Agreement - Expected_Agreement) / (1 - Expected_Agreement)\n",
    "        continue_loop = abs(alpha - previous_alpha) > 0.00001\n",
    "\n",
    "    Aikens_Alpha = alpha\n",
    "\n",
    "    # Calculation of the Standard Deviation\n",
    "    Proababilty_Difference_Rows = Probability_Rows[1:] - Probability_Rows[0]\n",
    "    Proababilty_Difference_Coloumns = Probability_Coloumns[1:] - Probability_Coloumns[0]\n",
    "\n",
    "    V = alpha / Expected_Agreement / ((1 - Aikens_Alpha) * Expected_Agreement + Aikens_Alpha)\n",
    "    T = 1 / Aikens_Alpha - 1\n",
    "    First_Second_Derivatives = -Sample_Size * (1 - Expected_Agreement) / (1 - Aikens_Alpha) / ((1 - Aikens_Alpha) * Expected_Agreement + Aikens_Alpha)\n",
    "    First_Second_Derivatives_Coloumns = -Weighted_Sum * Proababilty_Difference_Coloumns * ((Sample_Size / Weighted_Sum) ** 2)\n",
    "    First_Second_Derivatives_Rows = -Weighted_Sum * Proababilty_Difference_Rows * ((Sample_Size / Weighted_Sum) ** 2)\n",
    "\n",
    "    Rows_Matrix = -np.sum(y[:, 0]) / (Probability_Coloumns[0] ** 2) + Weighted_Sum * (2 * Expected_Agreement * T + 1) * V**2 * np.outer(Proababilty_Difference_Rows, Proababilty_Difference_Rows)\n",
    "    Rows_Term = -Sum_Of_Coloumns[1:] / (Probability_Coloumns[1:] ** 2) - Sum_Of_Coloumns[0] / (Probability_Coloumns[0] ** 2) + Weighted_Sum * (2 * Expected_Agreement * T + 1) * V **2 * (Proababilty_Difference_Rows ** 2)\n",
    "    np.fill_diagonal(Rows_Matrix, Rows_Term)\n",
    "\n",
    "    Coloumns_Matrix = -np.sum(y[0, :]) / (Probability_Rows[0] ** 2) + Weighted_Sum * (2 * Expected_Agreement * T + 1) * V**2 * np.outer(Proababilty_Difference_Coloumns, Proababilty_Difference_Coloumns)\n",
    "    Cols_Term = -Sum_Of_Rows[1:] / (Probability_Rows[1:] ** 2) - Sum_Of_Rows[0] / (Probability_Rows[0] ** 2) + Weighted_Sum * (2 * Expected_Agreement * T + 1) * V**2 * (Proababilty_Difference_Coloumns ** 2)\n",
    "    np.fill_diagonal(Coloumns_Matrix, Cols_Term)\n",
    "\n",
    "    Rows_Coloumns_Matrix = -Weighted_Sum * V + Weighted_Sum * (2 * Expected_Agreement * T + 1) * V**2 * np.outer(Proababilty_Difference_Coloumns, Proababilty_Difference_Rows).T\n",
    "    Rows_Cols_Term = -2 * Weighted_Sum * V + Weighted_Sum * (2 * Expected_Agreement * T + 1) * V **2 * Proababilty_Difference_Rows * Proababilty_Difference_Coloumns\n",
    "    np.fill_diagonal(Rows_Coloumns_Matrix, Rows_Cols_Term)\n",
    "\n",
    "    Var_Matrix_Top = np.concatenate(([First_Second_Derivatives], First_Second_Derivatives_Rows, First_Second_Derivatives_Coloumns))\n",
    "    Var_Matrix_Center = np.column_stack((np.matrix(First_Second_Derivatives_Rows).T, Rows_Matrix, Rows_Coloumns_Matrix))\n",
    "    Var_Matrix_Bottom = np.column_stack((np.matrix(First_Second_Derivatives_Coloumns).T, Rows_Coloumns_Matrix.T, Coloumns_Matrix))\n",
    "    Var_Matrix_Final = np.vstack((Var_Matrix_Top, Var_Matrix_Center, Var_Matrix_Bottom))\n",
    "    Covariance_Matrix = np.linalg.inv(-Var_Matrix_Final)\n",
    "\n",
    "    Aikens_Standart_Deviation = np.sqrt(Covariance_Matrix[0, 0])\n",
    "\n",
    "    # Confidence Interval\n",
    "    zcrit = scipy.stats.t.ppf(1 - (1 - confidence_level) / 2, 100000)\n",
    "    LowerCi = Aikens_Alpha - zcrit * Aikens_Standart_Deviation\n",
    "    UpperCi = Aikens_Alpha + zcrit * Aikens_Standart_Deviation\n",
    "\n",
    "\n",
    "    results= {}\n",
    "\n",
    "    results[\"Aiken's Alpha\"]= Aikens_Alpha\n",
    "    results[\"Aiken's Standard Deviation \"]= Aikens_Standart_Deviation\n",
    "    #results[\"Statistic Z\"] = Z_statistic\n",
    "    #results[\"p_value\"] = p_value\n",
    "    results[\"Confidence Intervals\"] = f\"({round(LowerCi, 4)}, {round(UpperCi, 4)})\"\n",
    "\n",
    "    result_str = \"\\n\".join([f\"{key}: {value}\" for key, value in results.items()])\n",
    "    return results\n",
    "\n",
    "Aiken_Alpha(data, 0.95)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
