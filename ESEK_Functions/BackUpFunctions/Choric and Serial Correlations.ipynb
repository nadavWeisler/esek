{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Odds Ratio': 5.6,\n",
       " 'Chambers r': 0.5229,\n",
       " 'Tetrachoric Correlation': 0.5953,\n",
       " 'Tetrachoric Approximation': 0.5631,\n",
       " 'Tetrachoric Corrected': 0.3689,\n",
       " 'Standard_Error_Tetrachoric': 0.1656,\n",
       " 'Standard_Error_Tetrachoric_Corrected': 0.2136,\n",
       " 'Phi': 0.3933,\n",
       " 'Phi chi square statistic': 7.5792,\n",
       " 'Phi p_value': 0.0059,\n",
       " 'maxphi': 1.2825,\n",
       " 'Max_Corrected_Phi)': 0.3067,\n",
       " 'Phi max_Corrected_p_value': 0.0318,\n",
       " 'Phi Variance': 0.0169076,\n",
       " 'chi square phi': 7.57924,\n",
       " 'chi square max corrected phi': 4.60818,\n",
       " \"Cramer's V)\": 0.3933,\n",
       " 'Bias Corrected Cramer)': 0.3975,\n",
       " 'Wallis Swing D (coloumns independent)': 0.4035,\n",
       " 'Wallis Swing D Standard Error': 0.14657,\n",
       " 'Wallis Percentage Swing (coloumns independent)': 0.6053,\n",
       " 'CI_swing_d_Wallis': '(0.1162, 0.6908)',\n",
       " 'CI_Percentage_swing_d_Wallis': '(0.1744, 1.0362)'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import scipy.special as special\n",
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as st\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, iqr, median_abs_deviation, beta, norm, nct, t, f, ncf, chi2,  median_test, hmean, wilcoxon, hypergeom, rankdata, mannwhitneyu, binom, fisher_exact, barnard_exact, chi2_contingency\n",
    "from scipy.special import hyp2f1\n",
    "from numpy import around, array2string\n",
    "import numpy as np\n",
    "import numpy as geek\n",
    "import math\n",
    "import random\n",
    "import itertools\n",
    "import statistics\n",
    "import researchpy as rp\n",
    "import pingouin as pg\n",
    "from pingouin import cochran\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "from collections import Counter\n",
    "import scipy.stats as stats\n",
    "import scipy.optimize as optimize\n",
    "from scipy.optimize import newton, root_scalar\n",
    "from scipy.stats.contingency import odds_ratio, relative_risk\n",
    "import rpy2.robjects as robjects\n",
    "from statsmodels.stats.contingency_tables import mcnemar, cochrans_q\n",
    "from statsmodels.stats.proportion import proportion_confint, confint_proportions_2indep\n",
    "from itertools import product\n",
    "\n",
    "a = 20\n",
    "b = 10\n",
    "c = 5\n",
    "d = 14\n",
    "confidence_level = 0.95\n",
    "\n",
    "def calculate_p_value_from_chi_score(chi_score, df):\n",
    "    p_value = st.chi2.sf((abs(chi_score)), df)\n",
    "    return min(float(p_value), 0.99999)\n",
    "\n",
    "\n",
    "def Binary_2x2_measures(a,b,c,d): \n",
    "    sample_size = a+b+c+d\n",
    "    Corrected_levels_Number = 2 - 1/(sample_size-1)\n",
    "    \n",
    "    \n",
    "    # Effect Sizes\n",
    "    Odds_Ratio = a*d/ (b*c)\n",
    "    Tetrachoric_Correlation = np.cos(3.14159265359 / (1 + np.sqrt(Odds_Ratio))) \n",
    "    Tetrachoric_Basic_Approximation = (Odds_Ratio**0.74 - 1) / (Odds_Ratio**0.74 + 1)\n",
    "    phi = (a*d - b*c) / np.sqrt((a+b)*(c+d)*(a+c)*(b+d))\n",
    "    Chambers_R = (((Odds_Ratio + 1)/(Odds_Ratio - 1))  -  ((2*Odds_Ratio * np.log(Odds_Ratio)) / (Odds_Ratio - 1)**2))\n",
    "    Cramer = phi\n",
    "    Bias_Corrected_Cramer = np.sqrt((phi**2/(Corrected_levels_Number-1)) ) # CORRECTION IS FROM BERGSMA 2013\n",
    "    \n",
    "    # Maximum Corrected Phi (See richard liu 1980)\n",
    "    max_phi1 = np.sqrt( (  (a+b)/(c+d)) * ((d+b) / (c+a)))\n",
    "    max_phi2 = np.sqrt( (  (a+c)/(b+d)) * ((a+b) / (c+d)))  \n",
    "    max_phi = max_phi1 if c + d > b + a else max_phi2\n",
    "    Max_Corrected_Phi = phi/max_phi\n",
    "\n",
    "    # Significance_of_phi and max corrected phi\n",
    "    chi_square_phi = phi**2*sample_size\n",
    "    p_value = calculate_p_value_from_chi_score(chi_square_phi, 1)\n",
    "    chi_square_max_corrected_phi = Max_Corrected_Phi**2*sample_size\n",
    "    p_value_max_Corrected_phi = calculate_p_value_from_chi_score(chi_square_max_corrected_phi, 1)\n",
    "\n",
    "    # Variance of phi (from Bishop et al's., book) (approximation for large samples)\n",
    "    p1_plus = (a +b)/sample_size # Marginal_Probability_Row1\n",
    "    p2_plus = (c +d)/sample_size # Marginal_Probability_Row2\n",
    "    pplus_1 = (a +c)/sample_size # Marginal_Probability_Coloumn1\n",
    "    pplus_2 = (b +d)/sample_size # Marginal_Probability_Coloumn2\n",
    "    Probabilities_Product = (p1_plus*p2_plus*pplus_1*pplus_2)\n",
    "    term1 =  phi + 0.5 * phi**3\n",
    "    term2 = ((p1_plus - p2_plus) * (pplus_1 - pplus_2)) / np.sqrt(Probabilities_Product)\n",
    "    term3 = 0.75*phi**2*(((p1_plus - p2_plus)**2 / (p1_plus * p2_plus)) + ((pplus_1 - pplus_2)**2 / (pplus_1 * pplus_2)))\n",
    "    Variance = (1/sample_size) * (1 - phi**2 + term1 * term2 - term3)\n",
    "\n",
    "    # Corrected Tetrachoric Correlaiton and Its Variance based on the odds ratio variance (Bonnet, 2005)\n",
    "    \n",
    "    # Preaper the Correction \n",
    "    r1 = (a + b + 1) / (sample_size + 2)\n",
    "    r2 = (c + d + 1) / (sample_size + 2)\n",
    "    c1 = (a + b + 1) / (sample_size + 2)\n",
    "    c2 = (c + d + 1) / (sample_size + 2)\n",
    "    Minimal_Probability = min(c1, c2, r1, r2)\n",
    "    Correction = (1 - abs(r1 - c1) / 5 - (0.5 - Minimal_Probability)**2) / 2\n",
    "    \n",
    "    Corrected_Odds_Ratio = (a + 0.5)*(b + 0.5)/((c + 0.5)*(d + 0.5))\n",
    "    Corrected_Tetrachoric_Correlation = np.cos(3.14159/ (1 + Corrected_Odds_Ratio**Correction))\n",
    "\n",
    "    Standard_Error_Odds_Ratio = np.sqrt(1/a + 1/b + 1/c + 1/d)\n",
    "    Standard_Error_Odds_Ratio_Corrected = np.sqrt(1 / (a + 0.5) + 1 / (b + 0.5) + 1 / (c + 0.5) + 1 / (d + 0.5))\n",
    "\n",
    "    K = (3.14159 * 0.5 * Odds_Ratio**0.5) * np.sin(3.14159 / (1 + Odds_Ratio**0.5)) / (1 + Odds_Ratio**0.5)**2\n",
    "    Corrected_K = (3.14159 * Correction * Corrected_Odds_Ratio**Correction) * np.sin(3.14159/(1 + Corrected_Odds_Ratio**Correction)) / (1 + Corrected_Odds_Ratio**Correction)**2\n",
    "    \n",
    "    Standard_Error_Tetrachoric = K * Standard_Error_Odds_Ratio_Corrected\n",
    "    Standard_Error_Tetrachoric_Corrected = Corrected_K * Standard_Error_Odds_Ratio_Corrected\n",
    "\n",
    "    #Wallis Swing and percentage Swing Measures\n",
    "    Wallis_Swing_d_coloumns_indpendnt =  a/(a+b) - c/(c+d)\n",
    "    Wallis_Perecentage_Swing_coloumns_independent =  Wallis_Swing_d_coloumns_indpendnt /  (a/(a+b))\n",
    "    Estimate = (a+c)/sample_size\n",
    "    Standard_Error_coloumns_independent = np.sqrt(( (Estimate*(1-Estimate)) * (1/(a+b)+(1/(c+d)))))\n",
    "    z_crit = st.norm.ppf(confidence_level + ((1 - confidence_level) / 2))\n",
    "    Lower_CI_swing_d_Wallis = Wallis_Swing_d_coloumns_indpendnt - Standard_Error_coloumns_independent*z_crit\n",
    "    Upper_CI_swing_d_Wallis = Wallis_Swing_d_coloumns_indpendnt + Standard_Error_coloumns_independent*z_crit\n",
    "    Lower_CI_Percentage_swing_d_Wallis = Lower_CI_swing_d_Wallis / (a/(a+b))\n",
    "    Upper_CI_Percentage_swing_d_Wallis = Upper_CI_swing_d_Wallis / (a/(a+b))\n",
    "\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    results[\"Odds Ratio\"] = round(Odds_Ratio, 4)\n",
    "    results[\"Chambers r\"] = round(Chambers_R, 4)\n",
    "    \n",
    "    # Tetrachoric Correlation\n",
    "    results[\"Tetrachoric Correlation\"] = round(Tetrachoric_Correlation, 4)\n",
    "    results[\"Tetrachoric Approximation\"] = round(Tetrachoric_Basic_Approximation, 4)\n",
    "    results[\"Tetrachoric Corrected\"] = round(Corrected_Tetrachoric_Correlation, 4)\n",
    "    results[\"Standard_Error_Tetrachoric\"] = round(Standard_Error_Tetrachoric, 4)\n",
    "    results[\"Standard_Error_Tetrachoric_Corrected\"] = round(Standard_Error_Tetrachoric_Corrected, 4)\n",
    "\n",
    "    # Phi and max phi\n",
    "    results[\"Phi\"] = round(phi, 4)\n",
    "    results[\"Phi chi square statistic\"] = round(chi_square_phi, 4)\n",
    "    results[\"Phi p_value\"] = round(p_value, 4)\n",
    "    results[\"maxphi\"] = round(max_phi, 4)\n",
    "    results[\"Max_Corrected_Phi)\"] = round(Max_Corrected_Phi, 4)\n",
    "    results[\"Phi max_Corrected_p_value\"] = round(p_value_max_Corrected_phi, 4)\n",
    "    results[\"Phi Variance\"] = round(Variance, 7)\n",
    "    results[\"chi square phi\"] = round(chi_square_phi, 5)\n",
    "    results[\"chi square max corrected phi\"] = round(chi_square_max_corrected_phi, 5)\n",
    "\n",
    "    # Other Basic Effect Sizes\n",
    "    results[\"Cramer's V)\"] = round(phi, 4)\n",
    "    results[\"Bias Corrected Cramer)\"] = round(Bias_Corrected_Cramer, 4)\n",
    "    results[\"chi square phi\"] = round(chi_square_phi, 5)\n",
    "\n",
    "\n",
    "    # Wallis Measures of effect size\n",
    "    results[\"Wallis Swing D (coloumns independent)\"] = round(Wallis_Swing_d_coloumns_indpendnt, 4)\n",
    "    results[\"Wallis Swing D Standard Error\"] = round(Standard_Error_coloumns_independent, 5)\n",
    "    results[\"Wallis Percentage Swing (coloumns independent)\"] = round(Wallis_Perecentage_Swing_coloumns_independent, 4)\n",
    "    results[\"CI_swing_d_Wallis\"] = f\"({round(Lower_CI_swing_d_Wallis, 4)}, {round(Upper_CI_swing_d_Wallis, 4)})\"\n",
    "    results[\"CI_Percentage_swing_d_Wallis\"] = f\"({round(Lower_CI_Percentage_swing_d_Wallis, 4)}, {round(Upper_CI_Percentage_swing_d_Wallis, 4)})\"\n",
    "\n",
    "\n",
    "    #result_str = \"\\n\".join([f\"{key}: {value}\" for key, value in results.items()])\n",
    "    #return result_str\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "Binary_2x2_measures(a,b,c,d)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
